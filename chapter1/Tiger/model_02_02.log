conv_1/Relu   [None, 222, 222, 64]
pool_1/MaxPool   [None, 111, 111, 64]
conv_2/Relu   [None, 109, 109, 128]
pool_2/MaxPool   [None, 54, 54, 128]
conv_3/Relu   [None, 52, 52, 256]
conv_4/Relu   [None, 50, 50, 256]
pool_3/MaxPool   [None, 25, 25, 256]
conv_5/Relu   [None, 23, 23, 512]
conv_6/Relu   [None, 21, 21, 512]
pool_4/MaxPool   [None, 10, 10, 512]
conv_7/Relu   [None, 8, 8, 512]
conv_8/Relu   [None, 6, 6, 512]
pool_5/MaxPool   [None, 3, 3, 512]
pool_5_reshape/Reshape   [None, 4608]
fc_1/Relu   [None, 512]
fc_2/Relu   [None, 512]
logits/BiasAdd   [None, 94]
let's training.
Loss at step 20： 4.368046283721924
Loss at step 40： 3.91497540473938
Loss at step 60： 4.012871742248535
Loss at step 80： 3.944024085998535
Loss at step 100： 3.8600516319274902
Loss at step 120： 3.6032493114471436
Average loss at epoch 1: 3.9930512322319878
Took: 140.48702692985535 seconds.
Accuracy at epoch 1: 0.2630258573184598
Took: 27.23595905303955 seconds.
Loss at step 140： 3.478884696960449
Loss at step 160： 3.419591188430786
Loss at step 180： 3.481325626373291
Loss at step 200： 3.229680061340332
Loss at step 220： 3.0458664894104004
Loss at step 240： 2.9552574157714844
Loss at step 260： 2.922813892364502
Average loss at epoch 2: 3.2436335263428866
Took: 137.13112020492554 seconds.
Accuracy at epoch 2: 0.4079072635406398
Took: 26.572079181671143 seconds.
Loss at step 280： 2.822190284729004
Loss at step 300： 3.0251758098602295
Loss at step 320： 2.640178918838501
Loss at step 340： 2.4594309329986572
Loss at step 360： 2.386617660522461
Loss at step 380： 2.4383034706115723
Loss at step 400： 2.4947752952575684
Average loss at epoch 3: 2.6052811393031368
Took: 136.39628553390503 seconds.
Accuracy at epoch 3: 0.5159972708247071
Took: 26.81320357322693 seconds.
Loss at step 420： 2.568175792694092
Loss at step 440： 2.3352575302124023
Loss at step 460： 2.0816006660461426
Loss at step 480： 1.8439013957977295
Loss at step 500： 1.9357391595840454
Loss at step 520： 2.0252346992492676
Loss at step 540： 1.6939868927001953
Average loss at epoch 4: 2.0867839451189396
Took: 135.9971945285797 seconds.
Accuracy at epoch 4: 0.6525104462331588
Took: 26.431304931640625 seconds.
Loss at step 560： 1.8399794101715088
Loss at step 580： 1.6861212253570557
Loss at step 600： 1.7048476934432983
Loss at step 620： 1.769202470779419
Loss at step 640： 2.041002035140991
Loss at step 660： 1.447547435760498
Average loss at epoch 5: 1.6687557706126461
Took: 137.60282230377197 seconds.
Accuracy at epoch 5: 0.6969927124517838
Took: 26.699455738067627 seconds.
Loss at step 680： 1.449556827545166
Loss at step 700： 1.4988834857940674
Loss at step 720： 1.4639849662780762
Loss at step 740： 1.3368369340896606
Loss at step 760： 1.3286583423614502
Loss at step 780： 1.05763578414917
Loss at step 800： 1.043531894683838
Average loss at epoch 6: 1.3812740626158537
Took: 137.70655393600464 seconds.
Accuracy at epoch 6: 0.7466257673618126
Took: 26.959452152252197 seconds.
Loss at step 820： 1.425927996635437
Loss at step 840： 1.586094856262207
Loss at step 860： 0.9024520516395569
Loss at step 880： 0.9241623878479004
Loss at step 900： 1.2340302467346191
Loss at step 920： 0.9799657464027405
Loss at step 940： 1.2629523277282715
Average loss at epoch 7: 1.1949354864932873
Took: 138.1522467136383 seconds.
Accuracy at epoch 7: 0.7438734094708576
Took: 26.941861629486084 seconds.
Loss at step 960： 1.29393470287323
Loss at step 980： 1.080717921257019
Loss at step 1000： 0.9110434651374817
Loss at step 1020： 0.9422715902328491
Loss at step 1040： 0.9598824381828308
Loss at step 1060： 0.871181070804596
Loss at step 1080： 0.9984344840049744
Average loss at epoch 8: 1.0668325026830037
Took: 138.90695548057556 seconds.
Accuracy at epoch 8: 0.7795210865684631
Took: 26.96081280708313 seconds.
Loss at step 1100： 0.7133458852767944
Loss at step 1120： 0.8833605051040649
Loss at step 1140： 1.0166538953781128
Loss at step 1160： 1.0813615322113037
Loss at step 1180： 1.2193313837051392
Loss at step 1200： 1.0691901445388794
Average loss at epoch 9: 0.9411641619823597
Took: 139.23443341255188 seconds.
Accuracy at epoch 9: 0.7877133486671595
Took: 26.956826210021973 seconds.
Loss at step 1220： 1.0487326383590698
Loss at step 1240： 0.8694638609886169
Loss at step 1260： 1.0833485126495361
Loss at step 1280： 0.7420149445533752
Loss at step 1300： 0.7139810919761658
Loss at step 1320： 0.6136167049407959
Loss at step 1340： 0.6455947160720825
Average loss at epoch 10: 0.8526016065367946
Took: 139.11942219734192 seconds.
Accuracy at epoch 10: 0.7738031911306704
Took: 26.818517923355103 seconds.
Loss at step 1360： 0.8665289878845215
Loss at step 1380： 1.059464693069458
Loss at step 1400： 0.846112847328186
Loss at step 1420： 0.7065176963806152
Loss at step 1440： 0.9183027744293213
Loss at step 1460： 0.7269057035446167
Loss at step 1480： 0.8489419221878052
Average loss at epoch 11: 0.7848758242748402
Took: 138.2163074016571 seconds.
Accuracy at epoch 11: 0.754467722308346
Took: 26.830336332321167 seconds.
Loss at step 1500： 0.809946596622467
Loss at step 1520： 0.6978282928466797
Loss at step 1540： 0.5623930096626282
Loss at step 1560： 0.4957078695297241
Loss at step 1580： 0.54747474193573
Loss at step 1600： 0.6131786108016968
Loss at step 1620： 0.608371376991272
Average loss at epoch 12: 0.7092556564896195
Took: 137.60760879516602 seconds.
Accuracy at epoch 12: 0.7836422641557421
Took: 27.21530771255493 seconds.
Loss at step 1640： 0.6747073531150818
Loss at step 1660： 0.6777034401893616
Loss at step 1680： 0.5760793685913086
Loss at step 1700： 0.8035221695899963
Loss at step 1720： 0.8513588309288025
Loss at step 1740： 0.6657989025115967
Average loss at epoch 13: 0.6370825058884091
Took: 137.35754299163818 seconds.
Accuracy at epoch 13: 0.7877351090874548
Took: 26.917243003845215 seconds.
Loss at step 1760： 0.6467891931533813
Loss at step 1780： 0.5085965991020203
Loss at step 1800： 0.8395382165908813
Loss at step 1820： 0.602573037147522
Loss at step 1840： 0.4467410445213318
Loss at step 1860： 0.42757371068000793
Loss at step 1880： 0.47744613885879517
Average loss at epoch 14: 0.6157597641150157
Took: 139.3863594532013 seconds.
Accuracy at epoch 14: 0.7612476911099799
Took: 26.789674520492554 seconds.
Loss at step 1900： 0.6545680165290833
Loss at step 1920： 0.7572231292724609
Loss at step 1940： 0.6621400117874146
Loss at step 1960： 0.5053725242614746
Loss at step 1980： 0.5931358933448792
Loss at step 2000： 0.42960143089294434
Loss at step 2020： 0.520388662815094
Average loss at epoch 15: 0.5806324735835746
Took: 138.45278191566467 seconds.
Accuracy at epoch 15: 0.7797082802279045
Took: 26.486292123794556 seconds.
Loss at step 2040： 0.5970435738563538
Loss at step 2060： 0.7599509954452515
Loss at step 2080： 0.3916754126548767
Loss at step 2100： 0.37843719124794006
Loss at step 2120： 0.5416042804718018
Loss at step 2140： 0.277084082365036
Loss at step 2160： 0.5195692777633667
Average loss at epoch 16: 0.5452915792111998
Took: 138.7280740737915 seconds.
Accuracy at epoch 16: 0.8030763583260643
Took: 26.292221069335938 seconds.
Loss at step 2180： 0.4890267252922058
Loss at step 2200： 0.7110704779624939
Loss at step 2220： 0.45201802253723145
Loss at step 2240： 0.6201047897338867
Loss at step 2260： 0.6027907133102417
Loss at step 2280： 0.5356206297874451
Average loss at epoch 17: 0.5283859851183714
Took: 136.40387773513794 seconds.
Accuracy at epoch 17: 0.7760092514195509
Took: 26.815040349960327 seconds.
Loss at step 2300： 0.7539418935775757
Loss at step 2320： 0.5586170554161072
Loss at step 2340： 0.6903584003448486
Loss at step 2360： 0.3179166913032532
Loss at step 2380： 0.3763026297092438
Loss at step 2400： 0.5656562447547913
Loss at step 2420： 0.39766237139701843
Average loss at epoch 18: 0.5093391748490157
Took: 137.43984746932983 seconds.
Accuracy at epoch 18: 0.7457135464872284
Took: 26.970072507858276 seconds.
Loss at step 2440： 0.46078866720199585
Loss at step 2460： 0.489099383354187
Loss at step 2480： 0.3975570797920227
Loss at step 2500： 0.34530264139175415
Loss at step 2520： 0.5927740335464478
Loss at step 2540： 0.4546582102775574
Loss at step 2560： 0.5298022031784058
Average loss at epoch 19: 0.5106798081486313
Took: 139.25586080551147 seconds.
Accuracy at epoch 19: 0.7279964872983848
Took: 27.337082147598267 seconds.
Loss at step 2580： 0.7174012660980225
Loss at step 2600： 0.690131664276123
Loss at step 2620： 0.44769811630249023
Loss at step 2640： 0.22951792180538177
Loss at step 2660： 0.35303276777267456
Loss at step 2680： 0.36261045932769775
Loss at step 2700： 0.7127168774604797
Average loss at epoch 20: 0.4978269275691774
Took: 138.56570291519165 seconds.
Accuracy at epoch 20: 0.7599228263756039
Took: 27.167418956756592 seconds.
Loss at step 2720： 0.4211188554763794
Loss at step 2740： 0.4107106924057007
Loss at step 2760： 0.33856427669525146
Loss at step 2780： 0.515379786491394
Loss at step 2800： 0.5298258662223816
Loss at step 2820： 0.4063498377799988
Average loss at epoch 21: 0.45235919532952484
Took: 137.43186855316162 seconds.
Accuracy at epoch 21: 0.7773787544110767
Took: 26.736186027526855 seconds.
Loss at step 2840： 0.4569656252861023
Loss at step 2860： 0.3695720434188843
Loss at step 2880： 0.4880440831184387
Loss at step 2900： 0.3226311206817627
Loss at step 2920： 0.2724592089653015
Loss at step 2940： 0.3474375903606415
Loss at step 2960： 0.2451358437538147
Average loss at epoch 22: 0.4024378335034406
Took: 137.96009492874146 seconds.
Accuracy at epoch 22: 0.7859493279454911
Took: 26.79778528213501 seconds.
Loss at step 2980： 0.40927964448928833
Loss at step 3000： 0.37616220116615295
Loss at step 3020： 0.45918887853622437
Loss at step 3040： 0.36766576766967773
Loss at step 3060： 0.3396180272102356
Loss at step 3080： 0.3484749495983124
Loss at step 3100： 0.287440687417984
Average loss at epoch 23: 0.3724509813167431
Took: 138.3550000190735 seconds.
Accuracy at epoch 23: 0.7780711923954235
Took: 27.34479069709778 seconds.
Loss at step 3120： 0.32766929268836975
Loss at step 3140： 0.3942468762397766
Loss at step 3160： 0.35459205508232117
Loss at step 3180： 0.36377039551734924
Loss at step 3200： 0.31690967082977295
Loss at step 3220： 0.23946508765220642
Loss at step 3240： 0.4899429380893707
Average loss at epoch 24: 0.38679763796152894
Took: 137.4783594608307 seconds.
Accuracy at epoch 24: 0.7677155085742998
Took: 26.931915998458862 seconds.
Loss at step 3260： 0.29658111929893494
Loss at step 3280： 0.2703368663787842
Loss at step 3300： 0.2322567254304886
Loss at step 3320： 0.720389723777771
Loss at step 3340： 0.42861461639404297
Loss at step 3360： 0.2902538776397705
Average loss at epoch 25: 0.3773318829359832
Took: 138.6473274230957 seconds.
Accuracy at epoch 25: 0.7566970752792482
Took: 26.375258445739746 seconds.
Loss at step 3380： 0.3207324743270874
Loss at step 3400： 0.36452969908714294
Loss at step 3420： 0.45115137100219727
Loss at step 3440： 0.6006338000297546
Loss at step 3460： 0.24106140434741974
Loss at step 3480： 0.362326055765152
Loss at step 3500： 0.2671738564968109
Average loss at epoch 26: 0.3793655642756709
Took: 136.81293177604675 seconds.
Accuracy at epoch 26: 0.7622182228186789
Took: 26.535481452941895 seconds.
Loss at step 3520： 0.34273624420166016
Loss at step 3540： 0.5420182943344116
Loss at step 3560： 0.25061675906181335
Loss at step 3580： 0.38623425364494324
Loss at step 3600： 0.32285845279693604
Loss at step 3620： 0.36673036217689514
Loss at step 3640： 0.32278403639793396
Average loss at epoch 27: 0.3533266813666732
Took: 138.1715259552002 seconds.
Accuracy at epoch 27: 0.7802767223534839
Took: 26.406391859054565 seconds.
Loss at step 3660： 0.511492908000946
Loss at step 3680： 0.3680134117603302
Loss at step 3700： 0.2759413719177246
Loss at step 3720： 0.2939814627170563
Loss at step 3740： 0.2816624343395233
Loss at step 3760： 0.13417348265647888
Loss at step 3780： 0.5075321197509766
Average loss at epoch 28: 0.3509482862772765
Took: 136.5780861377716 seconds.
Accuracy at epoch 28: 0.7486564782920831
Took: 26.444825410842896 seconds.
Loss at step 3800： 0.37522369623184204
Loss at step 3820： 0.20759694278240204
Loss at step 3840： 0.15426091849803925
Loss at step 3860： 0.4021846652030945
Loss at step 3880： 0.2933087646961212
Loss at step 3900： 0.1812637895345688
Average loss at epoch 29: 0.34187477534567867
Took: 137.37146019935608 seconds.
Accuracy at epoch 29: 0.7663014347486792
Took: 26.86949586868286 seconds.
Loss at step 3920： 0.40956997871398926
Loss at step 3940： 0.5288661122322083
Loss at step 3960： 0.3617264926433563
Loss at step 3980： 0.1632782518863678
Loss at step 4000： 0.44138604402542114
Loss at step 4020： 0.3233991861343384
Loss at step 4040： 0.2935929298400879
Average loss at epoch 30: 0.371976743693705
Took: 137.24571180343628 seconds.
Accuracy at epoch 30: 0.7727365047273289
Took: 26.57658886909485 seconds.
